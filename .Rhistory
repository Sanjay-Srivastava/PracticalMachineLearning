require(data.table)
df = fread(sprintf("bzcat %s | tr -d '\\000'", "file.csv.bz2"))
?gbm
library(gbm)
?gbm
version("gbm")
package_version("gbm")
package_version(gbm)
library(gbm)
package_version(gbm)
package_version("gbm")
source('~/GitHub/MachineLearning/temp1.R')
model_gbm
model_gbm$fit
class(model_gbm$fit)
class(train_gbm)
train_gbm
dim(train_gbm)
length(train_gbm)
model_gbm$data
class(model_gbm$data)
source('~/GitHub/MachineLearning/temp1.R')
head(train_gbm)
head(valid_gbm)
head(test_gbm)
confusionMatrix(train_gbm, std_train$classe)
confusionMatrix(valid_gbm, std_valid$classe)
x = list(rep(1, 10))
x
y = list(rep(2, 10))
z = data.frame( x = x, y = y)
z
z = data.frame( col1 = x, col2 = y)
z
str(z)
names(z) = c("col1", "col2")
z
class(x)
class(y)
class(z)
xyz = data.frame(z, col3 = x, col4 = y)
xyz
source('~/GitHub/MachineLearning/temp1.R')
test_rf
class(test_rf)
test_gbm
class(test_gbm)
x = data.frame(std_test, rf = test_rf, gbm = test_gbm)
x
a = c(1:5)
b = c(6:10)
c = rbind( r1 = a, r2 = b)
c
class(c)
c[,] = c[,]/rowsum(c[,])
c = data.frame(rbind( r1 = a, r2 = b))
c
c$x1 = c$x1/rowsums(c$r1)
c$x1 = c$x1/rowsum(c$r1)
rowsum(c$r1)
rowsum(c)
rowsum(c[,])
rowsum(c[1,])
rowsum(c[,1])
summary(c)
summary(a,b)
summary(a ~ b)
prop.table(a,b)
prop.table(table(a,b))
prop.table(c)
prop.table(c,1)
?prop.table
prop.table(a)
prop.table(b)
getOption(warning())
getOption(warnings())
getOption(warnings
)
getOption(warning)
getOption("warning")
getOption("warnings")
training1 = read.csv("c://users/sanjaysr/documents/GitHub/MachineLearning/pml-training.csv",
header = T)
testing1  = read.csv("c://users/sanjaysr/documents/GitHub/MachineLearning/pml-testing.csv",
header = T)
training1$classe = factor(training1$classe) ## factorize the column: CLASSE
na_test = sapply(testing1, function(x)
ifelse( sum( is.na(x) | x == "" | x == "#DIV/0!" | x == "NA" ) == 0,
"Include" ,
"Exclude"
)
)
# columns containing sensor data
cols = grep(pattern = "_belt|_arm|_dumbbell|_forearm", names(testing1))
# final list of valuable columns in the testing data
covars = names(na_test)[na_test == "Include" & cols]
covars = covars[8:59]
set.seed(12345)
idx = createDataPartition(training2$classe, p = 0.6, list = FALSE)
raw_train = training2[idx, ]
raw_valid = training2[-idx, ]
dim(raw_train  )
dim(raw_valid  )
str(raw_train)
df = raw_train[1, -classe]
df = raw_train[1, -1]
str(df)
tdf = t(df)
str(tdf)
head(tdf)
rm(tdf)
tdf
my_svd = svd(preProcess(raw_train, method = c("center", "scale")))
my_svd = svd(preProcess(df, method = c("center", "scale")))
my_svd = svd(preProcess(df, method = c("center", "scale", "knnimpute")))
my_svd = svd(preProcess(df, method = c("center", "scale", "knnImpute")))
df = preProcess(df, method = c('center','scale'))
df = preProcess(raw_train[, covars])
df = preProcess(raw_train[, covars], method = c("center","scale"))
df = preProcess(raw_train[, covars], method = c("center","scale", "knnImpute"))
svd_df = svd(df)
svd_df = svd(as.matrix(df))
is.finite(df)
is.finite(df[,1])
is.finite(df[1])
names(df)
head(df)
dim(df)
class(df)
df$dim
df$rotation
df$pcaComp
df$bc
df$yj
df$et
df$mean
df$std
df$ranges
df$trace
df$thresh
df$numComp
df$ica
df$k
df$knnSummary()
knnSummary(df)
df$bagImp
df$median
df$data
dim(df$data)
df = preProcess(raw_train[, covars], method = "pca")
df
df$dim
df$bc
df$ranges
df$et
df$bc
df$yj
df$rotation
class(df$rotation)
names(df$rotation)
rownames(df$rotation)
df$rotation
df
df$thresh
df$pcaComp
df$k
df$bagImp
write.csv(df$rotation, "c:/users/sanjaysr/documents/github/machinelearning/pca_analysis.csv")
prcomp(raw_train[, covars])
prcomp(raw_train[, covars])
x = prcomp(raw_train[, covars])
class(x)
x$x
dim(x$x)
dim$rotation
x$rotation
plot(x[,1], x[, 2])
z = prcomp(raw_train)
z = prcomp(raw_train[, covars])
plot(z$x[,1], z$x[,2])
plot(z$x[,1], z$x[,2], col = typeColor)
library(ggplot2)
plot(z$x[,1], z$x[,2], col = typeColor)
plot(z$x[,1], z$x[,2], col = c(1,2))
df = preProcess(raw_train[, covars], method = "pca")
dfp = predict(df, raw_train[, covars], method = "glm")
confusionMatrix(dfp, raw_train$classe)
training1 = read.csv("c://users/sanjaysr/documents/GitHub/MachineLearning/pml-training.csv",
header = T)
testing1  = read.csv("c://users/sanjaysr/documents/GitHub/MachineLearning/pml-testing.csv",
header = T)
training1$classe = factor(training1$classe) ## factorize the column: CLASSE
na_test = sapply(testing1, function(x)
ifelse( sum( is.na(x) | x == "" | x == "#DIV/0!" | x == "NA" ) == 0,
"Include" ,
"Exclude"
)
)
# columns containing sensor data
cols = grepl(pattern = "_belt|_arm|_dumbbell|_forearm", names(testing1))
# final list of valuable columns in the testing data
covars = names(na_test)[na_test == "Include" & cols]
covars
covars = covars[8:59]
set.seed(12345)
idx = createDataPartition(training2$classe, p = 0.6, list = FALSE)
raw_train = training2[idx, ]
raw_valid = training2[-idx, ]
?varImpPlot
?randomForest
?varImpPlot
env("testing1")
is.loaded("testing1")
is.loaded(testing1)
dff = "x"
isloaded("dff")
is.loaded("dff")
exists("dff")
exists("sanjay")
?exists
?confusionMatrix
getwd()
load("./GitHub/MachineLearning/model_rf.RDATA")
std_valid = read.csv("./GitHub/MachineLearning/Data/std_valid.csv")
x = 1
y = 2
z = 3
exists(x)
exists("x")
exists(c("x", "y"))
exists(c("x", "y", "a"))
a
exists("a")
x = c("a", "b")
y = c("b", "c")
z = intersect(x, y)
z
getwd()
testing = read.csv("./GitHub/MachineLearning/Data/pml-testing.csv")
hasValidData = sapply(testing, function(x)
ifelse( sum( is.na(x) | x == "" | x == "#DIV/0!" | x == "NA" ) == 0,
TRUE ,
FALSE
)
)
hasValidData
nams(hasValidData)
names(hasValidData)
testing = read.csv("./GitHub/MachineLearning/Data/pml-testing.csv")
load("./GitHub/MachineLearning/Objects/predObj_test_rf")
load("./GitHub/MachineLearning/Objects/predObj_test_rf.RDATA")
std_valid = read.csv("./GitHub/MachineLearning/Data/std_valid.csv")
load("./GitHub/MachineLearning/Objects/predObj_valid_rf.RDATA")
confusionMatrix(predObj_valid_rf, std_valid$classe)
load("./GitHub/MachineLearning/Objects/modelObj_rf.RDATA")
modelObj_rf$err.rate
modelObj_rf$oob.times
modelObj_rf$type
modelObj_rf$predicted
modelObj_rf$inbag
modelObj_rf$terms
modelObj_rf$confusion
modelObj_rf$votes
modelObj_rf$classes
modelObj_rf$localImportance
modelObj_rf$proximity
setwd("./GitHub/MachineLearning")
load("./Objects/cmObj_valid_rf")
load("./Objects/cmObj_valid_rf.RData")
load("./Objects/cmObj_valid_rf.RData")
cmObj_valid_rf
cmObj_valid_rf$overall
load("./Objects/cmObj_valid_gbm.RData")
cmObj_valid_gbm$overall
cmObj_valid_gbm$positive
cmObj_valid_gbm$byClass
cmObj_valid_rf$byClass
cmObj_valid_rf$dots
cmObj_valid_rf$dots[1]
load("./Objects/model_rf.RDATA")
load("./Objects/modelObj_rf.RDATA")
modelObj_rf
modelObj_rf$ntree
modelObj_rf$mtry
modelObj_rf$confusion
modelObj_rf$forest
